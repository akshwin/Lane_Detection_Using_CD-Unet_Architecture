{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6b966574-d898-4d00-9b08-385e27ccd6db",
      "metadata": {
        "id": "6b966574-d898-4d00-9b08-385e27ccd6db"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dT-rsI1WR1Y3",
      "metadata": {
        "id": "dT-rsI1WR1Y3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc410252-6075-4f1c-9fe6-3759eb3de339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_XGAVv5lR2NB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XGAVv5lR2NB",
        "outputId": "09ec74e8-27a1-4c27-df14-ad7155ea0537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/hikmatullahmohammadi/tusimple-preprocessed\n",
            "License(s): unknown\n",
            "tusimple-preprocessed.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  tusimple-preprocessed.zip\n",
            "replace tusimple_preprocessed/test/frames/0530_1492626047222176976_0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# download dataset\n",
        "!kaggle datasets download -d hikmatullahmohammadi/tusimple-preprocessed\n",
        "# unzip dataset\n",
        "!unzip tusimple-preprocessed.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "58e216af-ce87-4252-b7a4-953bdc056b30",
      "metadata": {
        "id": "58e216af-ce87-4252-b7a4-953bdc056b30"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "np.random.seed(42)\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 3\n",
        "TRAIN_PATH = \"/content/tusimple_preprocessed/training/frames\"\n",
        "TRAIN_MASKS_PATH = '/content/tusimple_preprocessed/training/lane-masks'\n",
        "TEST_PATH = '/content/tusimple_preprocessed/test/frames'\n",
        "TEST_MASKS_PATH = '/content/tusimple_preprocessed/test/lane-masks'\n",
        "\n",
        "train_image_files = os.listdir(TRAIN_PATH)\n",
        "train_mask_files = os.listdir(TRAIN_MASKS_PATH)\n",
        "test_image_files = os.listdir(TEST_PATH)\n",
        "test_mask_files = os.listdir(TEST_MASKS_PATH)\n",
        "\n",
        "X_train = np.zeros((1000, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
        "Y_train = np.zeros((1000, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
        "\n",
        "# X_train = np.zeros((len(train_image_files), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
        "# Y_train = np.zeros((len(train_image_files), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
        "# X_test = np.zeros((len(test_image_files), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
        "\n",
        "\n",
        "images = []\n",
        "masks = []\n",
        "for n, image_file in enumerate(train_image_files):\n",
        "    if os.path.splitext(image_file)[1].lower() == \".jpg\" and n < 1000:\n",
        "      image_path = os.path.join(TRAIN_PATH, image_file)\n",
        "      image = cv2.imread(image_path)\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      image = cv2.resize(image, (256,256))\n",
        "      image = image / 255\n",
        "\n",
        "      images.append(image)\n",
        "\n",
        "mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
        "for n, mask_file in enumerate(train_mask_files):\n",
        "    if os.path.splitext(mask_file)[1].lower() == \".jpg\" and n < 1000:\n",
        "      mask_path = os.path.join(TRAIN_MASKS_PATH, mask_file)\n",
        "      mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "      mask = cv2.resize(mask, (256,256))\n",
        "      mask = mask / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "      masks.append(np.expand_dims(mask, axis=-1))\n",
        "\n",
        "\n",
        "X_train, Y_train = np.array(images), np.array(masks)\n",
        "#print(np.min(Y_train), np.max(Y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f3bca4e-59a7-40cd-9569-8af711a700f4",
      "metadata": {
        "id": "2f3bca4e-59a7-40cd-9569-8af711a700f4"
      },
      "outputs": [],
      "source": [
        "num_images_to_display = 5\n",
        "\n",
        "selected_indices = np.random.choice(len(X_train), num_images_to_display, replace=False)\n",
        "\n",
        "for i, idx in enumerate(selected_indices):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    # Display the original image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(X_train[idx])\n",
        "    plt.title(f\"Original Image {idx}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Display the corresponding mask\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(Y_train[idx].squeeze(), cmap='gray')\n",
        "    plt.title(f\"Ground Truth Mask {idx}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66717bd0-33a7-4e60-8427-0df9dc3c421f",
      "metadata": {
        "id": "66717bd0-33a7-4e60-8427-0df9dc3c421f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_unet_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    inputs = tf.keras.layers.Input(input_shape)\n",
        "    s = inputs\n",
        "\n",
        "    # Contraction path\n",
        "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    # Expansive path\n",
        "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "def create_cascaded_unet_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    # Create the first U-Net model\n",
        "    unet1 = create_unet_model(input_shape=input_shape)\n",
        "\n",
        "    # Define the input for the cascaded U-Net\n",
        "    inputs = tf.keras.layers.Input(input_shape)\n",
        "\n",
        "    # Pass the input through the first U-Net\n",
        "    unet1_output = unet1(inputs)\n",
        "\n",
        "    # Create the second U-Net model\n",
        "    unet2 = create_unet_model(input_shape=input_shape)\n",
        "\n",
        "    # Pass the output of the first U-Net as input to the second U-Net\n",
        "    cascaded_output = unet2(unet1_output)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[cascaded_output])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b67ba51-7427-4b46-8f15-4c063fe6854f",
      "metadata": {
        "id": "7b67ba51-7427-4b46-8f15-4c063fe6854f"
      },
      "outputs": [],
      "source": [
        "#tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "with strategy.scope():\n",
        "    model = create_unet_model()\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#print(np.min(Y_train), np.max(Y_train))\n",
        "callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
        "        tf.keras.callbacks.ModelCheckpoint('model_for_lane.keras', verbose=1, save_best_only=True)]\n",
        "\n",
        "results = model.fit(X_train, Y_train, batch_size=16, epochs=25,steps_per_epoch=62,validation_split=0.1, callbacks=callbacks)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b0cc45e-f228-49ed-9a75-27418eea961e",
      "metadata": {
        "id": "0b0cc45e-f228-49ed-9a75-27418eea961e"
      },
      "outputs": [],
      "source": [
        "X_test = np.zeros((320, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
        "Y_test = np.zeros((320, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
        "# X_test = np.zeros((len(test_image_files), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
        "# Y_test = np.zeros((len(test_image_files), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
        "\n",
        "test = []\n",
        "test_masks = []\n",
        "for n, image_file in enumerate(test_image_files):\n",
        "    if os.path.splitext(image_file)[1].lower() == \".jpg\" and n < 320:\n",
        "      image_path = os.path.join(TEST_PATH, image_file)\n",
        "      image = cv2.imread(image_path)\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      image = cv2.resize(image, (256,256))\n",
        "      image = image / 255\n",
        "\n",
        "      test.append(image)\n",
        "\n",
        "mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
        "for n, mask_file in enumerate(test_mask_files):\n",
        "    if os.path.splitext(mask_file)[1].lower() == \".jpg\" and n < 320:\n",
        "      mask_path = os.path.join(TEST_MASKS_PATH, mask_file)\n",
        "      mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "      mask = cv2.resize(mask, (256,256))\n",
        "      mask = mask / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "      test_masks.append(np.expand_dims(mask, axis=-1))\n",
        "\n",
        "X_test, Y_test = np.array(test), np.array(test_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dc24542-afc3-4c5f-a6bc-7de49d35e946",
      "metadata": {
        "id": "9dc24542-afc3-4c5f-a6bc-7de49d35e946"
      },
      "outputs": [],
      "source": [
        "# trained U-Net model\n",
        "model = load_model('/content/model_for_lane.h5')\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "num_samples = 5  # Adjust the number of samples to visualize\n",
        "\n",
        "fig, axes = plt.subplots(num_samples, 3, figsize=(10, 3*num_samples))\n",
        "\n",
        "for i in range(num_samples):\n",
        "\n",
        "    # original image\n",
        "    axes[i, 0].imshow(X_test[i])\n",
        "    axes[i, 0].set_title(\"Original Image\")\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # ground truth mask\n",
        "    axes[i, 1].imshow(Y_test[i].squeeze(), cmap='gray')\n",
        "    axes[i, 1].set_title(\"Ground Truth Mask\")\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "    # predicted mask\n",
        "    axes[i, 2].imshow(y_pred[i].squeeze(), cmap='gray')\n",
        "    axes[i, 2].set_title(\"Predicted Mask\")\n",
        "    axes[i, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4648927d-29e2-4721-b1f9-afd81a4b1803",
      "metadata": {
        "id": "4648927d-29e2-4721-b1f9-afd81a4b1803"
      },
      "outputs": [],
      "source": [
        "# Plot the validation and training curves seprately\n",
        "def plot_loss_curves(history):\n",
        "    \"\"\"\n",
        "    Returns seprate loss curves for training and validation metrics.\n",
        "    \"\"\"\n",
        "    loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "    accuracy = history.history[\"accuracy\"]\n",
        "    val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "    epochs = range(len(history.history[\"loss\"])) # how many epochs did we run for?\n",
        "\n",
        "    # Plot loss\n",
        "    plt.plot(epochs,loss,label=\"training_loss\")\n",
        "    plt.plot(epochs,val_loss,label=\"val_loss\")\n",
        "    plt.title(\"Loss Curve\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.figure()\n",
        "    plt.plot(epochs,accuracy,label=\"training_accuracy\")\n",
        "    plt.plot(epochs,val_accuracy,label=\"val_accuracy\")\n",
        "    plt.title(\"\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.title('Accuracy Curve')\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QbUTKAt0bHAA",
      "metadata": {
        "id": "QbUTKAt0bHAA"
      },
      "outputs": [],
      "source": [
        "# Check out the loss and accuracy of model_4\n",
        "plot_loss_curves(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aqlcHZ8ibhse",
      "metadata": {
        "id": "aqlcHZ8ibhse"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}